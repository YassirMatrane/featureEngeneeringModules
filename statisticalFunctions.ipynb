{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics \n",
    "import pandasql as ps\n",
    "\n",
    "\n",
    "class StatisticalFunctions:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def getCount(self):\n",
    "        return self.df.count()\n",
    "    \n",
    "    def getShape(self):\n",
    "        shape = self.df.shape\n",
    "        return {\"rows\":shape[0],\"columns\":shape[1]}\n",
    "      \n",
    "    def getQuantiles(self,column):\n",
    "        return {\"Q1\":self.df[column].quantile(0.25),\"Q2\":self.df[column].quantile(0.75)}\n",
    "    \n",
    "    def getMean(self,column):\n",
    "        return np.mean(self.df[column])\n",
    "\n",
    "    #It works after removig all the NaN values\n",
    "    def getFMean(self,column):\n",
    "        return statistics.harmonic_mean(self.df[column])\n",
    "\n",
    "    def getMedian(self,column):\n",
    "        return statistics.median(self.df[column])\n",
    "\n",
    "    def getLowMedian(self,column):\n",
    "        return statistics.median_low(self.df[column])\n",
    "    \n",
    "    def getHighMedian(self,column):\n",
    "        return statistics.median_high(self.df[column])\n",
    "    \n",
    "    def getGroupedMedian(self,column):\n",
    "        return statistics.median_grouped(self.df[column])\n",
    "    \n",
    "    def mode(self,column):\n",
    "        try:\n",
    "            return statistics.mode(self.df[column])\n",
    "        except:\n",
    "            print(\"either There is no mode, or more than one\")\n",
    "    \n",
    "    #Measures of spread\n",
    "    #These functions calculate a measure of how much the population or sample tends to deviate from the typical or average values.\n",
    "    #mu – This parameter is an optional. It is the mean of given data. \n",
    "    #If this parameter is missing or None, the mean of data is automatically calculated\n",
    "    #Return the sample standard deviation \n",
    "    def pstdev(self,column, mu = None):\n",
    "        return statistics.pstdev(self.df[column])\n",
    "    \n",
    "    #Retun the population standard deviation \n",
    "    def stdev(self,column, mu = None):\n",
    "        return statistics.stdev(self.df[column])\n",
    "    \n",
    "    #Row standard deviation of the dataframe\n",
    "    def stdevRow(self, mu = None):\n",
    "        return self.df.std(axis=1)\n",
    "    \n",
    "    def variance(self,column, xbar=None):\n",
    "        return statistics.variance(column)\n",
    "    \n",
    "    def pVariance(self,column, xbar=None):\n",
    "        return statistics.pvariance(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       5.196152\n",
      "1      10.016653\n",
      "2      15.821926\n",
      "3      20.663978\n",
      "4      19.008770\n",
      "5      27.209067\n",
      "6      52.548390\n",
      "7      10.785793\n",
      "8      34.428670\n",
      "9      10.408330\n",
      "10     99.874922\n",
      "11     14.849242\n",
      "12    197.989899\n",
      "dtype: float64\n",
      "Oops! There is no mode\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame({'salary':[1,2,33,4,22,41,100,3,7,14,200,23,313],'age':[10,11,12,15,40,90,8,20,17,19,35,np.nan,np.nan],'feature':[10,22,43,44,2,45,10,23,71,34,20,2,33]})\n",
    "sF = StatisticalFunctions(df)\n",
    "print(sF.stdevRow())\n",
    "print(sF.mode(\"salary\"))\n",
    "#[1,2,3,4,2,4,100,3,7,4,200,2,33]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Datasets: Merge and Join\n",
    "\n",
    "In this section, we will get over on how and when to combine our data in Pandas with:\n",
    "\n",
    "- merge() for combining data on common columns or indices\n",
    "\n",
    "When you want to combine data objects based on one or more keys in a similar way to a relational database, merge() is the tool you need. More specifically, merge() is most useful when you want to combine rows that share data.\n",
    "- join() for combining data on a key column or an index\n",
    "\n",
    "While merge() is a module function, .join() is an object function that lives on your DataFrame. This enables you to specify only one DataFrame, which will join the DataFrame you call .join() on.\n",
    "Under the hood, .join() uses merge(), but it provides a more efficient way to join DataFrames than a fully specified merge() call. \n",
    "- concat() for combining DataFrames across rows or columns\n",
    "\n",
    "Concatenation is a bit different from the merging techniques you saw above. With merging, you can expect the resulting dataset to have rows from the parent datasets mixed in together, often based on some commonality. Depending on the type of merge, you might also lose rows that don’t have matches in the other dataset.\n",
    "With concatenation, your datasets are just stitched together along an axis — either the row axis or column axis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombiningDataSet:\n",
    "    def __init__(self, df1,df2,df3,df4):\n",
    "        self.df1 = df1\n",
    "        self.df2 = df2\n",
    "        self.df3 = df3\n",
    "        self.df4 = df4\n",
    "        \n",
    "    def mergeOneToOne(self):\n",
    "        return pd.merge(self.df1, self.df2)\n",
    "    \n",
    "    #join =>{inner,outer,left,right}\n",
    "    def mergeOnJoin(self,columns,join=\"outer\"):\n",
    "        return pd.merge(self.df1,self.df2,how=join,on=columns)\n",
    "    \n",
    "    def mergeOnIndex(self):\n",
    "        return pd.merge(self.df1,self.df2,left_index=True, right_index=True)\n",
    "    \n",
    "    #In case, where two input DataFrames have conflicting column names\n",
    "    def mergeBySuffix(self,column,suffixes=[\"_L\", \"_R\"]):\n",
    "         return pd.merge(self.df1,self.df2,on=column,suffixes=suffixes)\n",
    "            \n",
    "    #axis : {0, 1, …}, default 0\n",
    "    #join : {‘inner’, ‘outer’}, default ‘outer’\n",
    "    #ignore_index : boolean, default False. If True, do not use the index values on the concatenation axis. \n",
    "    def concat(self,frames,axis=0,join=\"outer\",ignore_index=False, keys=None,sort=True):\n",
    "        return pd.concat(frames,axis=axis,join=join, ignore_index=ignore_index, keys=keys,sort=sort)\n",
    "    \n",
    "    def appendRow(self,row,ignore_index=True):\n",
    "        return self.df1.append(row, ignore_index=True)\n",
    "    \n",
    "    def groupBy(self,columns):\n",
    "        return self.df1.groupby(columns)\n",
    "    \n",
    "    def groupByFilter(self,groupedDT,column,value):\n",
    "        return groupedDT.filter(lambda x : x[column].mean() > value)        \n",
    "    \n",
    "    def aggrGroupedDT(self,groupedData):\n",
    "        return groupedData.agg([np.sum, np.mean, np.std,np.max,np.min,np.median,np.var,\"count\"])\n",
    "    \n",
    "    #Index level may be specified as keys or names\n",
    "    def groupByLevelMean(self,level=0):\n",
    "        return self.df1.groupby(level=0).mean()\n",
    "    \n",
    "    def groupByLevelMin(self,level=0):\n",
    "        return self.df1.groupby(level=0).min()\n",
    "    \n",
    "    def groupByLevelMax(self,level=0):\n",
    "        return self.df1.groupby(level=0).max()\n",
    "    \n",
    "    def groupByLevelSum(self,level=0):\n",
    "        return self.df1.groupby(level=0).sum()\n",
    "    \n",
    "    def groupByLevelCount(self,level=0):\n",
    "        return self.df1.groupby(level=0).count()\n",
    "    \n",
    "    def groupByLevelMedian(self,level=0):\n",
    "        return self.df1.groupby(level=0).median()\n",
    "    \n",
    "    #Reshaping by stacking and unstacking    \n",
    "    def stack(self):\n",
    "        return self.df1.stack()\n",
    "    \n",
    "    def unstack(self):\n",
    "        return self.df1.unstack()\n",
    "    \n",
    "    #Transposition \n",
    "    def transpose(self):\n",
    "        return self.df1.transpose()\n",
    "    \n",
    "    #Arithmetic operations\n",
    "    def add(self,value):\n",
    "        return self.df1+value\n",
    "    \n",
    "    def addDfToDt(self):\n",
    "        return self.df1*self.df2\n",
    "    \n",
    "    def multiplyByValue(self,value):\n",
    "        return self.df1*value\n",
    "    \n",
    "    def extract(self,value):\n",
    "        return value/self.df1\n",
    "    \n",
    "    def power(self,value):\n",
    "        return self.df1**value\n",
    "    \n",
    "    def operationsOnColumn(self,value,column,operation):\n",
    "        if operation==\"+\":\n",
    "            self.df1[column]=self.df1[column]+value\n",
    "        elif operation==\"*\":\n",
    "            self.df1[column]=self.df1[column]*value \n",
    "        elif operation==\"-\":\n",
    "            self.df1[column]=self.df1[column]-value\n",
    "        elif operation==\"**\":\n",
    "            self.df1[column]=self.df1[column]**value\n",
    "        elif operation==\"/\":\n",
    "            self.df1[column]=self.df1[column]/value\n",
    "        return self.df1\n",
    "    \n",
    "    def query(self,q):    \n",
    "        return ps.sqldf(q, locals())\n",
    "    \n",
    "    def querySQL(self,q,con):\n",
    "        return pd.read_sql_query(q,con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = {'Customer_id':pd.Series([1,2,3,4,5,6]),\n",
    "  'Product':pd.Series(['Oven','Oven','Oven','Television','Television','Television'])}\n",
    "df1m = pd.DataFrame(d1)\n",
    " \n",
    "d2 = {'Customer_id':pd.Series([2,4,6,7,8]),\n",
    "    'State':pd.Series(['California','California','Texas','New York','Indiana'])}\n",
    "df2m = pd.DataFrame(d2)\n",
    "\n",
    "\n",
    "df1 = pd.DataFrame({'employee': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "                    'group': ['Accounting', 'Engineering', 'Engineering', 'HR']})\n",
    "\n",
    "df2 = pd.DataFrame({'employee': ['Lisa', 'Bob', 'Jake', 'Sue'],\n",
    "                    'hire_date': [2004, 2008, 2012, 2014]})\n",
    "\n",
    "df3 = pd.DataFrame({'name': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "                    'rank': [1, 2, 3, 4]})\n",
    "\n",
    "df4 = pd.DataFrame({'name': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "                    'rank': [3, 1, 4, 2]})\n",
    "\n",
    "df1a = df1.set_index('employee')\n",
    "df2a = df2.set_index('employee')\n",
    "\n",
    "\n",
    "df1c = pd.DataFrame({'A': ['A10', 'A13', 'A12', 'A33'],\n",
    "                    'B': ['B10', 'B11', 'B12', 'B13'],\n",
    "                    'C': ['C20', 'C21', 'C22', 'C23'],\n",
    "                    'D': ['D0', 'D1', 'D22', 'D23']},\n",
    "                 index=[0, 1, 2, 3])\n",
    "\n",
    "df2c = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\n",
    "                    'B': ['B4', 'B5', 'B6', 'B7'],\n",
    "                    'C': ['C4', 'C5', 'C6', 'C7'],\n",
    "                    'D': ['D4', 'D5', 'D6', 'D7']},\n",
    "                   index=[4, 5, 6, 7])\n",
    "\n",
    "df3c = pd.DataFrame({'A': ['A8', 'A9', 'A10', 'A11'],\n",
    "                    'B': ['B8', 'B9', 'B10', 'B11'],\n",
    "                    'C': ['C8', 'C9', 'C10', 'C11'],\n",
    "                    'D': ['D8', 'D9', 'D10', 'D11']},\n",
    "                   index=[8, 9, 10, 11])\n",
    "\n",
    "df4c = pd.DataFrame({'B': ['B2', 'B3', 'B6', 'B7'],\n",
    "                    'D': ['D2', 'D3', 'D6', 'D7'],\n",
    "                    'F': ['F2', 'F3', 'F6', 'F7']},\n",
    "                    index=[2, 3, 6, 7])\n",
    "\n",
    "dfg = pd.DataFrame({\n",
    "    'value':[20.45,22.89,32.12,111.22,33.22,100.00,99.99],\n",
    "    'product':['table','chair','chair','mobile phone','table','mobile phone','table']})\n",
    "\n",
    "arrays = [['Falcon', 'Falcon', 'Parrot', 'Parrot'],\n",
    "          ['Captive', 'Wild', 'Captive', 'Wild']]\n",
    "index = pd.MultiIndex.from_arrays(arrays, names=('Animal', 'Type'))\n",
    "df = pd.DataFrame({'Max Speed': [390., 350., 30., 20.]},\n",
    "                  index=index)\n",
    "\n",
    "row = pd.Series(['X0', 'X1', 'X2', 'X3'], index=['A', 'B', 'C', 'D'])\n",
    "\n",
    "pieces = {'x': df1c, 'y': df2c, 'z': df3c}\n",
    "\n",
    "frames = [df1c, df2c, df3c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Customer_id     Product       State\n",
      "0            2        Oven  California\n",
      "1            4  Television  California\n",
      "2            6  Television       Texas\n",
      "\n",
      "\n",
      "                group  hire_date\n",
      "employee                        \n",
      "Bob        Accounting       2008\n",
      "Jake      Engineering       2012\n",
      "Lisa      Engineering       2004\n",
      "Sue                HR       2014\n",
      "\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [name, rank]\n",
      "Index: []\n",
      "\n",
      "\n",
      "   name  rank_L  rank_R\n",
      "0   Bob       1       3\n",
      "1  Jake       2       1\n",
      "2  Lisa       3       4\n",
      "3   Sue       4       2\n",
      "\n",
      "\n",
      "Testing groupby \n",
      "\n",
      "    value       product\n",
      "0   20.45         table\n",
      "1   22.89         chair\n",
      "2   32.12         chair\n",
      "3  111.22  mobile phone\n",
      "4   33.22         table\n",
      "5  100.00  mobile phone\n",
      "6   99.99         table\n",
      "               value                                                           \\\n",
      "                 sum     mean        std    amax    amin   median         var   \n",
      "product                                                                         \n",
      "chair          55.01   27.505   6.526596   32.12   22.89   27.505    42.59645   \n",
      "mobile phone  211.22  105.610   7.933738  111.22  100.00  105.610    62.94420   \n",
      "table         153.66   51.220  42.715956   99.99   20.45   33.220  1824.65290   \n",
      "\n",
      "                    \n",
      "             count  \n",
      "product             \n",
      "chair            2  \n",
      "mobile phone     2  \n",
      "table            3  \n"
     ]
    }
   ],
   "source": [
    "coDaSe = CombiningDataSet(df1m,df2m,None,None)\n",
    "print(coDaSe.mergeOnJoin('Customer_id',\"inner\"))\n",
    "print(\"\\n\")\n",
    "\n",
    "coDaSe1 = CombiningDataSet(df1a,df2a,None,None)\n",
    "print(coDaSe1.mergeOnIndex()) \n",
    "print(\"\\n\")\n",
    "\n",
    "coDaSe2 = CombiningDataSet(df3,df4,None,None)\n",
    "print(coDaSe2.mergeOneToOne())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(coDaSe2.mergeBySuffix(\"name\"))\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "#Testing groupby\n",
    "print(\"Testing groupby \\n\")\n",
    "coDaSe2 = CombiningDataSet(dfg,None,None,None)\n",
    "\n",
    "groupedData = coDaSe2.groupBy(\"product\")\n",
    "print(coDaSe2.groupByFilter(groupedData,'value',4))\n",
    "print(coDaSe2.aggrGroupedDT(groupedData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  A0  B0  C0  D0\n",
      "1  A1  B1  C1  D1\n",
      "2  A2  B2  C2  D2\n",
      "3  A3  B3  C3  D3\n",
      "4  X0  X1  X2  X3\n",
      "\n",
      "\n",
      "     A    B    C    D    B    D    F\n",
      "0   A0   B0   C0   D0  NaN  NaN  NaN\n",
      "1   A1   B1   C1   D1  NaN  NaN  NaN\n",
      "2   A2   B2   C2   D2   B2   D2   F2\n",
      "3   A3   B3   C3   D3   B3   D3   F3\n",
      "6  NaN  NaN  NaN  NaN   B6   D6   F6\n",
      "7  NaN  NaN  NaN  NaN   B7   D7   F7\n",
      "\n",
      "\n",
      "        A    B    C    D\n",
      "x 0    A0   B0   C0   D0\n",
      "  1    A1   B1   C1   D1\n",
      "  2    A2   B2   C2   D2\n",
      "  3    A3   B3   C3   D3\n",
      "y 4    A4   B4   C4   D4\n",
      "  5    A5   B5   C5   D5\n",
      "  6    A6   B6   C6   D6\n",
      "  7    A7   B7   C7   D7\n",
      "z 8    A8   B8   C8   D8\n",
      "  9    A9   B9   C9   D9\n",
      "  10  A10  B10  C10  D10\n",
      "  11  A11  B11  C11  D11\n",
      "\n",
      "\n",
      "    A   B   C   D   B   D   F\n",
      "2  A2  B2  C2  D2  B2  D2  F2\n",
      "3  A3  B3  C3  D3  B3  D3  F3\n",
      "\n",
      "  Reusing the exact index from the original DataFrame\n",
      "    A   B   C   D    B    D    F\n",
      "0  A0  B0  C0  D0  NaN  NaN  NaN\n",
      "1  A1  B1  C1  D1  NaN  NaN  NaN\n",
      "2  A2  B2  C2  D2   B2   D2   F2\n",
      "3  A3  B3  C3  D3   B3   D3   F3\n",
      "\n",
      " Ignoring indexes on the concatenation axis\n",
      "     A   B    C   D    F\n",
      "0   A0  B0   C0  D0  NaN\n",
      "1   A1  B1   C1  D1  NaN\n",
      "2   A2  B2   C2  D2  NaN\n",
      "3   A3  B3   C3  D3  NaN\n",
      "4  NaN  B2  NaN  D2   F2\n",
      "5  NaN  B3  NaN  D3   F3\n",
      "6  NaN  B6  NaN  D6   F6\n",
      "7  NaN  B7  NaN  D7   F7\n",
      "\n",
      " Using dict to define keys\n",
      "        A    B    C    D\n",
      "x 0    A0   B0   C0   D0\n",
      "  1    A1   B1   C1   D1\n",
      "  2    A2   B2   C2   D2\n",
      "  3    A3   B3   C3   D3\n",
      "y 4    A4   B4   C4   D4\n",
      "  5    A5   B5   C5   D5\n",
      "  6    A6   B6   C6   D6\n",
      "  7    A7   B7   C7   D7\n",
      "z 8    A8   B8   C8   D8\n",
      "  9    A9   B9   C9   D9\n",
      "  10  A10  B10  C10  D10\n",
      "  11  A11  B11  C11  D11\n"
     ]
    }
   ],
   "source": [
    "# Testing concat\n",
    "coDaSe3 = CombiningDataSet(df1c,df2c,df3c,df4c)\n",
    "print(coDaSe3.appendRow(row, ignore_index=True))\n",
    "print(\"\\n\")\n",
    "print(coDaSe3.concat([df1c, df4c], axis=1, sort=False))\n",
    "print('\\n')\n",
    "print(coDaSe3.concat(frames, keys=['x', 'y', 'z']))\n",
    "print(\"\\n\")\n",
    "print(coDaSe3.concat([df1c, df4c], axis=1, join='inner'))\n",
    "print(\"\\n  Reusing the exact index from the original DataFrame\")\n",
    "print(coDaSe3.concat([df1c, df4c.reindex(df1c.index)], axis=1))\n",
    "print('\\n Ignoring indexes on the concatenation axis')\n",
    "print(coDaSe3.concat([df1c, df4c], ignore_index=True, sort=False))\n",
    "print(\"\\n Using dict to define keys\")\n",
    "print(coDaSe3.concat(pieces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Max Speed\n",
      "Animal           \n",
      "Falcon          2\n",
      "Parrot          2\n",
      "        Max Speed\n",
      "Animal           \n",
      "Falcon      370.0\n",
      "Parrot       25.0\n",
      "        Max Speed\n",
      "Animal           \n",
      "Falcon      350.0\n",
      "Parrot       20.0\n",
      "        Max Speed\n",
      "Animal           \n",
      "Falcon      390.0\n",
      "Parrot       30.0\n",
      "        Max Speed\n",
      "Animal           \n",
      "Falcon      370.0\n",
      "Parrot       25.0\n",
      "        Max Speed\n",
      "Animal           \n",
      "Falcon      740.0\n",
      "Parrot       50.0\n"
     ]
    }
   ],
   "source": [
    "coDaSe4 = CombiningDataSet(df,None,None,None)\n",
    "print(coDaSe4.groupByLevelCount(level=0))\n",
    "print(coDaSe4.groupByLevelMean(level=0))\n",
    "print(coDaSe4.groupByLevelMin(level=0))\n",
    "print(coDaSe4.groupByLevelMax(level=0))\n",
    "print(coDaSe4.groupByLevelMedian(level=0))\n",
    "print(coDaSe4.groupByLevelSum(level=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animal  Type              \n",
      "Falcon  Captive  Max Speed    390.0\n",
      "        Wild     Max Speed    350.0\n",
      "Parrot  Captive  Max Speed     30.0\n",
      "        Wild     Max Speed     20.0\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "       Max Speed       \n",
      "Type     Captive   Wild\n",
      "Animal                 \n",
      "Falcon     390.0  350.0\n",
      "Parrot      30.0   20.0\n",
      "\n",
      "\n",
      "Animal     Falcon         Parrot      \n",
      "Type      Captive   Wild Captive  Wild\n",
      "Max Speed   390.0  350.0    30.0  20.0\n"
     ]
    }
   ],
   "source": [
    "print(coDaSe4.stack())\n",
    "print(\"\\n\")\n",
    "print(coDaSe4.unstack())\n",
    "print(\"\\n\")\n",
    "print(coDaSe4.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operations on dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1o = pd.DataFrame({'A': [1, 2, 3], 'B': [3, 4, 8]})\n",
    "df2o = pd.DataFrame({'A': [1, 2, 4], 'C': [7, 5, 9]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A   B\n",
      "0  110  13\n",
      "1  210  14\n",
      "2  310  18\n",
      "\n",
      "\n",
      "      A   B\n",
      "0  1000  30\n",
      "1  2000  40\n",
      "2  3000  80\n",
      "\n",
      "\n",
      "          A         B\n",
      "0  0.100000  3.333333\n",
      "1  0.050000  2.500000\n",
      "2  0.033333  1.250000\n",
      "\n",
      "\n",
      "                     A           B\n",
      "0  7766279631452241920       59049\n",
      "1  2123646838278979584     1048576\n",
      "2  4988285203979960320  1073741824\n",
      "\n",
      "\n",
      "      A   B\n",
      "0  1000  30\n",
      "1  2000  40\n",
      "2  3000  80\n",
      "\n",
      "\n",
      "      A  B\n",
      "0  1000  3\n",
      "1  2000  4\n",
      "2  3000  8\n",
      "\n",
      "\n",
      "       A   B   C\n",
      "0   1000 NaN NaN\n",
      "1   4000 NaN NaN\n",
      "2  12000 NaN NaN\n"
     ]
    }
   ],
   "source": [
    "coDaSe5 = CombiningDataSet(df1o,df2o,None,None)\n",
    "\n",
    "print(coDaSe5.add(10))\n",
    "print(\"\\n\")\n",
    "print(coDaSe5.multiplyByValue(10))\n",
    "print(\"\\n\")\n",
    "print(coDaSe5.extract(10))\n",
    "print(\"\\n\")\n",
    "print(coDaSe5.power(10))\n",
    "print(\"\\n\")\n",
    "print(coDaSe5.multiplyByValue(10))\n",
    "print(\"\\n\")\n",
    "print(coDaSe5.operationsOnColumn(10,\"A\",\"*\"))\n",
    "print(\"\\n\")\n",
    "print(coDaSe5.addDfToDt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
