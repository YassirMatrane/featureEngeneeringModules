{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing values\n",
    "\n",
    "Missing values should be handled carefully to avoid their affecting analyses. Whatever missing value is chosen, it should be used consistently throughout all data associated files and identified in the metadata and/or data description files, otherwise we should identify the missing values by analysing each column, which is our case.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Identifying missing values\n",
    "Missing values need to be handled because they reduce the quality for any of our performance metric. It can also lead to wrong prediction or classification and can also cause a high bias for any \n",
    "given model being used.\n",
    "\n",
    "Depending on data sources, missing data are identified differently. Pandas always identify missing values as NaN. However, unless the data has been pre-processed to a degree that an analyst will encounter missing values as NaN. Missing values can appear as a question mark (?) or a zero (0) or minus one (-1) or a blank. As a result, it is always important that a data scientist always perform exploratory data analysis (EDA)\n",
    "\n",
    "\n",
    "## 2) handling missing values\n",
    "\n",
    "There are several options for handling missing values each with its own PROS and CONS. However, the choice of what should be done is largely dependent on the nature of our data and the missing values.\n",
    "We have 2 options\n",
    " ### 1) Imputation\n",
    "   #### 1.1) Fill missing values with statistical methods\n",
    "   Computing the overall mean, median or mode is a very basic imputation method, it is the only tested function that takes no advantage of the time series characteristics or relationship between the variables. It is very fast, but has clear disadvantages like it only works on the column level and will give poor results on encoded categorical features.\n",
    "   \n",
    "   Most Frequent is another statistical strategy to impute missing values. It works with categorical features.\n",
    "   \n",
    "   Hot-Deck imputation that works by randomly choosing the missing value from a set of related and similar variables. \n",
    "   \n",
    "   #### Note 1: \n",
    "   Linear Interpolation works well for a time series with some trend but is not suitable for seasonal data\n",
    "   #### Note 2: \n",
    "   For longitudinal data, such as patients’ weights over a period of visits, it might make sense to use last valid \n",
    "   observation to fill the NA’s. This is known as Last observation carried forward (LOCF).\n",
    "   \n",
    "   #### 1.2) predict missing values with a machine learning algorithm\n",
    "   This is by far one of the best and most efficient method for handling missing data. Depending on the class of data that is missing, one can either use a regression model or classification to predict missing data. This works by turning missing features to labels themselves and now using columns without missing values to predict columns with missing values.\n",
    "   \n",
    "   The only drawback to this approach is that if there is no correlation between attributes with missing data and other attributes in the data set, then the model will be bias for predicting missing values.\n",
    "   \n",
    "   ##### 1.2.1) Linear Regression\n",
    "   Mean, median or mode imputation only look at the distribution of the values of the variable with missing entries. If we know there is a correlation between the missing value and other variables, we can often get better guesses by regressing the missing variable on other variables.\n",
    "   \n",
    "   ##### 1.2.2) K Nearest Neighbors\n",
    "   The distance metric varies according to the type of data:\n",
    "   Continuous Data: The commonly used distance metrics for continuous data are Euclidean, Manhattan and Cosine\n",
    "   Categorical Data: Hamming distance is generally used in this case. It takes all the categorical attributes and for each, count one if the value is not the same between two points. \n",
    "   \n",
    "   Despite performance of K-NN, it is quite sensitive to outliers in the data (unlike SVM)\n",
    "   ##### 1.2.3) XGBoost\n",
    "   ##### 1.2.4) Random forest\n",
    "   ##### 1.2.5) Deep Learning (Datawig)\n",
    "   This method works very well with categorical and non-numerical features. It is a library that learns Machine Learning models using Deep Neural Networks to impute missing values in a dataframe. It also supports both CPU and GPU for training.\n",
    "   \n",
    "   This method is quite accurate compared to others but, you have to specify the columns that contain information about the target column that will be imputed, moreover it works with a single column.\n",
    "   \n",
    "   \n",
    "   #### For more information == > https://datawig.readthedocs.io/en/latest/source/userguide.html#overview-of-datawig\n",
    "   \n",
    "   ##### 1.2.6) logistic regression & ANOVA for prediction\n",
    "   \n",
    "   #### Note 3: \n",
    "   Multiple Imputations (MIs) are much better than a single imputation as it measures the uncertainty of the missing values in a better way by using Markov Chain Monte Carlo (MCMC) simulation in case we have an arbitrary\n",
    "missing data pattern, otherwise we use for instance a parametric regression method.\n",
    "#### Article ==> Multiple Imputation for Missing Data: Concepts and New Development\n",
    "\n",
    "#### Autoimpute is a Python package for analysis and implementation of Imputation Methods!\n",
    "\n",
    "  #### Note 4:\n",
    "  Multivariate imputer that estimates each feature from all the others.\n",
    "A strategy for imputing missing values by modeling each feature with missing values as a function of other features in a round-robin fashion. This new approache is still at the experimental stage in the sci-kit learn library. \n",
    " The IterativeImputer package allows the flexibility to choose a pre-loaded sci-kit learn model to iterate through the data to impute missing values.\n",
    " \n",
    " #### Best practices ==> https://scikit-learn.org/stable/auto_examples/impute/plot_iterative_imputer_variants_comparison.html#sphx-glr-auto-examples-impute-plot-iterative-imputer-variants-comparison-py\n",
    " \n",
    " #### Articles ==> Multivariate Imputation by Chained Equations in R && Statistical Analysis with Missing Data\n",
    " \n",
    " #### Note 5: \n",
    " Interpolation is a mathematical method that adjusts a function to your data and uses this function to extrapolate the missing data. The most simple type of interpolation is the linear interpolation, that makes a mean between the values before the missing data and the value after.\n",
    "\n",
    "Combining these two techniques (Seasonal Adjustment and Linear Interpolation) may be better.\n",
    " \n",
    " #### Article ==> Comparison of Linear Interpolation Method and Mean Method to Replace the Missing Values in Environmental Data Set\n",
    "#### 1.3) Interpolation\n",
    "Interpolation is a mathematical method that adjusts a function to your data and uses this function to extrapolate the missing data. The most simple type of interpolation is the linear interpolation, that makes a mean between the values before the missing data and the value after.\n",
    "\n",
    " ### 2) Deletion\n",
    " This is the fastest and easiest step to handle missing values. However, it is not generally advised. This method reduces the quality of our model as it reduces sample size\n",
    " #### 2.1) Listwise\n",
    "Listwise deletion (complete-case analysis) removes all data for an observation that has one or more missing values. Particularly if the missing data is limited to a small number of observations, you may just opt to eliminate those cases from the analysis. However in most cases, it is often disadvantageous to use listwise deletion. This is because the assumptions of MCAR (Missing Completely at Random) are typically rare to support. As a result, listwise deletion methods produce biased parameters and estimates.\n",
    "#### 2.2) Pairwise\n",
    "Pairwise deletion is an alternative to listwise deletion to mitigate the loss of data.\n",
    "It analyses all cases in which the variables of interest are present and thus maximizes all data available by an analysis basis.\n",
    "The strength to this technique is that it increases power in your analysis but it has many disadvantages.It assumes that the missing data are completely at random. If you delete pairwise then you’ll end up with different numbers of observations contributing to different parts of your model, which can make interpretation difficult.\n",
    "\n",
    "This approach is not implemented yet.\n",
    "\n",
    "#### Article ==> Pairwise deletion for missing data in structural equation models\n",
    "#### 2.3) Dropping Variables\n",
    "There are situations when the variable has a lot of missing values, in this case, if the variable is not a very important predictor for the target variable, the variable can be dropped completely. As a rule of thumb, when the data goes missing on 60–70 percent of the variable, dropping the variable should be considered. \n",
    "\n",
    "### 3) Dealing with categorical data \n",
    "#### 3.1) Identifying Categorical Data: Nominal, Ordinal and Continuous\n",
    "Categorical features can only take on a limited, and usually fixed, number of possible values. For example, if a dataset is about information related to users, then you will typically find features like country, gender, age group, etc. Alternatively, if the data you're working with is related to products, you will find features like product type, manufacturer, seller and so on.\n",
    "\n",
    "These are all categorical features in your dataset. These features are typically stored as text values which represent various traits of the observations. For example, gender is described as Male (M) or Female (F), product type could be described as electronics, apparels, food etc.\n",
    "\n",
    "- Note that these type of features where the categories are only labeled without any order of precedence are called nominal features.\n",
    "\n",
    "- Features which have some order associated with them are called ordinal features. For example, a feature like economic status, with three categories: low, medium and high, which have an order associated with them.\n",
    "\n",
    "- There are also continuous features. These are numeric variables that have an infinite number of values between any two values. A continuous variable can be numeric or a date/time.\n",
    "\n",
    "#### 3.2) Encoding Categorical Data\n",
    "You will now learn different techniques to encode the categorical features to numeric quantities. To keep it simple, you will apply these encoding methods only on the carrier column. However, the same approach can be extended to all columns.\n",
    "\n",
    "The techniques that you'll cover are the following:\n",
    "\n",
    "- Replacing values\n",
    "- Encoding labels\n",
    "- One-Hot encoding\n",
    "- Binary encoding\n",
    "- Backward difference encoding\n",
    "- Miscellaneous features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First of all, we have to declare Missing Value by replacing the specified values of the selected attributes by Double.NaN, Thus these values will be treated as missing values, hence we will get the unique values from the selected column, in order to identify meaningless values.\n",
    "\n",
    "- Then, we check the percentenge of missing values for each column, in order to define which one needs to be dropped, otherwise we can drop data that goes missing on a specified threshold.\n",
    "\n",
    "- Afterwards, we can remove rows depending on a threshold that defines how many columns have NaN.\n",
    "- Finally, we can impute missing values either by statistical methods or by using machine learning algorithms to predict missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Iterable\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from modules.encoding import Encoding\n",
    "\n",
    "class MissingValues:\n",
    "    def __init__(self, df,meaninglessVals = [\"?\",\"Na\",\"na\",\"\",\" \",'None',\"nan\",\"nane\",\"none\"]):\n",
    "        self.df = df    \n",
    "        self.meaninglessVals=meaninglessVals\n",
    "    def collectMisVal(self,misVals):\n",
    "        return self.meaninglessVals.append(misVals)\n",
    "    def getUniqueValues(self,column):\n",
    "        return list(self.df[column].unique())\n",
    "    def replace(self,column,val,reVal):\n",
    "        self.df[column].replace(val,reVal,inplace=True) \n",
    "    def replaceMisCategorical(self,column):\n",
    "        self.df[column].replace(np.nan,\"unknown\",inplace=True)\n",
    "    def replaceMeaninglessVals(self):\n",
    "        self.df.replace(self.meaninglessVals,np.nan,inplace=True) \n",
    "    def replaceStr(self,column,stri):\n",
    "        self.df[column].replace(stri,np.nan, inplace=True)\n",
    "    def replaceByRegex(self,exp): \n",
    "        self.df.replace(to_replace=exp, value = np.nan, regex = True,inplace=True)\n",
    "    def getInfCols(self):\n",
    "        percent_missing = self.df.isnull().sum() * 100 / len(self.df)\n",
    "        missing_value_df = pd.DataFrame({'column_name': self.df.columns,\n",
    "                                 'percent_missing': percent_missing})\n",
    "        missing_value_df.sort_values('percent_missing', inplace=True)\n",
    "        return missing_value_df   \n",
    "    \n",
    "    def getColumnsType(self):\n",
    "        dictTypes = {'object':[],'int':[],'float':[],'bool':[],'time':[],'category':[]}\n",
    "        for col in self.df.columns:\n",
    "            dtype = str(self.df[col].dtype)\n",
    "            if \"object\" in dtype:\n",
    "                dictTypes['object'].insert(0,col)\n",
    "            elif \"int\" in dtype:\n",
    "                dictTypes['int'].insert(0,col)\n",
    "            elif \"float\" in dtype:\n",
    "                dictTypes['float'].insert(0,col)\n",
    "            elif \"bool\" in dtype:\n",
    "                dictTypes['bool'].insert(0,col)  \n",
    "            elif \"category\" in dtype:\n",
    "                dictTypes['category'].insert(0,col)  \n",
    "\n",
    "            else:\n",
    "                dictTypes['time'].insert(0,col)\n",
    "        return dictTypes        \n",
    "    \n",
    "    def fillna(self,column,replacedVal):\n",
    "        return self.df[column].fillna(replacedVal)\n",
    "\n",
    "    def dropColumns(self,columns):\n",
    "        self.df.drop(columns, axis=1, inplace=True)\n",
    "        \n",
    "    #Supprimer toutes les colonnes surpassant le pourcentage assigné comme paramètre\n",
    "    def dropAutomColumns(self,nan_percent = 0.7):\n",
    "        threshold = len(self.df.index) * nan_percent\n",
    "        columns = [c for c in self.df.columns if sum(self.df[c].isnull()) >= threshold]\n",
    "        for column in columns:\n",
    "            self.df.drop(column,axis = 1,inplace=True)\n",
    "            \n",
    "    #Supprimer les colonnes suivant le seuil du nombre des valeurs nulles \n",
    "    def dropRowsCo(self,threshold = 1):\n",
    "        self.df.dropna(thresh=threshold,axis=1,inplace=True)\n",
    "        \n",
    "    #Supprimer les lignes suivant le seuil du nombre des valeurs nulles\n",
    "    def dropRowsRo(self,threshold=1):\n",
    "        self.df.dropna(thresh=threshold,axis=0,inplace=True)\n",
    "\n",
    "    def dropRows(self,columns):\n",
    "        self.df.dropna(subset=columns,inplace=True)\n",
    "            \n",
    "    #method ==> {‘linear’, ‘time’, ‘index’, ‘values’, ‘nearest’, ‘zero’,‘slinear’, ‘quadratic’, ‘cubic’, ‘barycentric’, ‘krogh’, ‘polynomial’, ‘spline’ ‘piecewise_polynomial’, ‘pchip’}\n",
    "    #limit_direction ==> {‘forward’, ‘backward’, ‘both’}\n",
    "    def interpolate(self,column,method,limDirec):\n",
    "        self.df[column].interpolate(method=method,limit_direction=limDirec,inplace=True)\n",
    "    def imputeRandomly(self, feature):\n",
    "        number_missing = self.df[feature].isnull().sum()\n",
    "        observed_values = self.df.loc[self.df[feature].notnull(), feature]\n",
    "        self.df.loc[self.df[feature].isnull(), feature] = np.random.choice(observed_values, number_missing, replace = True)\n",
    "        \n",
    "    def imputeByStatiMeth(self,strategy,column):\n",
    "        if strategy==\"mean\":\n",
    "            self.df[column].fillna((self.df[column].mean()), inplace=True)\n",
    "        elif strategy==\"median\":\n",
    "            self.df[column].fillna((self.df[column].median()), inplace=True)\n",
    "        elif strategy ==\"random\":\n",
    "            self.df[column].fillna(list(df['A'].sample())[0], inplace=True)\n",
    "        return self.df\n",
    "        \n",
    "    #inputCols = variables indépendantes & outpulCol = variable indépendante\n",
    "    def imputeByKNN(self,knn=3):\n",
    "        # imputation (knn) s'applique sur toutes les colonnes\n",
    "        imputer = KNNImputer(n_neighbors=knn)\n",
    "        self.df = imputer.fit_transform(self.df)\n",
    "            \n",
    "    def imputeByPred(self,algorithm,inputCols,outputCol,categoricalVal=None,knn = 3):\n",
    "        #Pour prédire les valeurs manquantes, on prend que les lignes dont il n'y'a pas de valeurs nulles\n",
    "\n",
    "        if categoricalVal == None:\n",
    "            newDf = self.df.copy()\n",
    "            inCols = inputCols\n",
    "            inputCols.append(outputCol)\n",
    "            train = newDf[inputCols].dropna()\n",
    "            inCols.remove(outputCol)\n",
    "            X_train = train[inCols].values.reshape(-1,len(inCols))       \n",
    "            y_train = train[outputCol].values.reshape(-1,1)\n",
    "            nans = self.df[outputCol].isnull()\n",
    "            nansY = self.df[nans][inCols]\n",
    "            dfPred = nansY[(nansY.notnull().all(1))]\n",
    "            indexP = dfPred.index\n",
    "        else:\n",
    "            X_train = self.df.loc[self.df[outputCol]!=categoricalVal,inputCols].values.reshape(-1,len(inputCols)) \n",
    "            y_train = self.df.loc[self.df[outputCol]!=categoricalVal,outputCol].values.reshape(-1,1) \n",
    "            dfPred = self.df.loc[self.df[outputCol]==categoricalVal,inputCols]\n",
    "            indexP = dfPred.index\n",
    "            \n",
    "        # imputation (knn) s'applique sur les colonnes passées sur les paramétres\n",
    "        # round ==> for example we have 2 classes and we got (0.60==>1) or (0.40==>0) threshold = 0.50\n",
    "        if algorithm == \"knn\":\n",
    "            model = KNeighborsClassifier(knn, weights='distance')\n",
    "            model.fit(X_train, y_train)\n",
    "            predictedValues = model.predict(dfPred)\n",
    "            if categoricalVal == None:\n",
    "                self.df.loc[indexP,outputCol] = predictedValues\n",
    "            else:\n",
    "                self.df.loc[indexP,outputCol] = [int(round(num)) for num in list(self.flat(predictedValues))]\n",
    "\n",
    "\n",
    "        elif algorithm == \"regression\":            \n",
    "            model = LinearRegression()\n",
    "            model.fit(X_train, y_train)\n",
    "            predictedValues = model.predict(dfPred)\n",
    "            if categoricalVal == None:\n",
    "                self.df.loc[indexP,outputCol] = predictedValues\n",
    "            else:\n",
    "                self.df.loc[indexP,outputCol] = [int(round(num)) for num in list(self.flat(predictedValues))]\n",
    "\n",
    "        elif algorithm == \"decisionTree\":\n",
    "            model = tree.DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
    "            model.fit(X_train, y_train)\n",
    "            predictedValues = model.predict(dfPred)\n",
    "            if categoricalVal == None:\n",
    "                self.df.loc[indexP,outputCol] = predictedValues\n",
    "            else:\n",
    "                self.df.loc[indexP,outputCol] = [int(round(num)) for num in list(self.flat(predictedValues))]\n",
    "\n",
    "        elif algorithm == \"randomForest\":\n",
    "            model = MultiOutputRegressor(RandomForestRegressor(max_depth=30,random_state=0))\n",
    "            model.fit(X_train, y_train)\n",
    "            predictedValues = model.predict(dfPred)\n",
    "            if categoricalVal == None:\n",
    "                self.df.loc[indexP,outputCol] = predictedValues\n",
    "            else:\n",
    "                self.df.loc[indexP,outputCol] = [int(round(num)) for num in list(self.flat(predictedValues))]\n",
    "\n",
    "    #reference ==> https://towardsdatascience.com/preprocessing-encode-and-knn-impute-all-categorical-features-fast-b05f50b4dfaa        \n",
    "    def encodeImpute(self,columns):\n",
    "        imputeData = self.df.copy()\n",
    "        dictFe = []\n",
    "        for col in columns:\n",
    "            if 'category' in str(self.df[col].dtype):\n",
    "                imputeData[col] = imputeData[col].astype(object, axis=0)\n",
    "        encoder = LabelEncoder()\n",
    "        imputer = IterativeImputer(ExtraTreesRegressor())\n",
    "        for col in columns:\n",
    "            dictF = Encoding.encode(imputeData[col])\n",
    "            dictFe.append((col,dictF))\n",
    "        self.df.drop(labels=columns, axis=\"columns\", inplace=True)\n",
    "        self.df = pd.merge(pd.DataFrame(np.round(imputer.fit_transform(imputeData)),columns = imputeData.columns),self.df)\n",
    "        return dictFe\n",
    "\n",
    "    ''''   \n",
    "    def imputeInterative(self,outputCol):        \n",
    "        #imp = IterativeImputer(missing_values=np.nan,n_nearest_features=2, initial_strategy=strategy)\n",
    "        #imp.fit([self.df[inputCols]])\n",
    "        #return imp.transform([self.df[outputCol]])\n",
    "        imp = IterativeImputer(max_iter=10, verbose=0)\n",
    "        imp.fit([self.df[outputCol]])\n",
    "        imputed_df = imp.transform([self.df[outputCol]])\n",
    "        imputed_df = pd.DataFrame(imputed_df, columns=self.df.columns)\n",
    "        return imputed_df\n",
    "    '''\n",
    "        \n",
    "        \n",
    "   \n",
    "    #### Convert from string to int\n",
    "\n",
    "    def convertToInt(self,col):\n",
    "        self.df[col] = pd.to_numeric(self.df[col],errors='coerce')\n",
    "\n",
    "    #flatten list\n",
    "    def flat(self,lst):\n",
    "        for parent in lst:\n",
    "            if not isinstance(parent, Iterable):\n",
    "                yield parent\n",
    "            else:\n",
    "                for child in self.flat(parent):\n",
    "                    yield child\n",
    "\n",
    "    #find id\n",
    "    def findAndRemoveId(self):\n",
    "        idsList = [\"id\",\"ID\",\"Id\"]\n",
    "        for iD in idsList:\n",
    "            try:\n",
    "                self.df.drop(iD,axis = 1,inplace = True)\n",
    "            except:\n",
    "                print(iD,\" doesn't exist in dataFrame\")\n",
    "                continue\n",
    "\n",
    "    #retour imputed DataFrame\n",
    "    def read(self):\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class Encoding:\n",
    " #### Encoding categorical data ###   \n",
    "    def encode(data):\n",
    "        #function to encode non-null data and replace it in the original data\n",
    "        encoder = LabelEncoder()\n",
    "        #retains only non-null values\n",
    "        nonulls = np.array(data.dropna())\n",
    "        #reshapes the data for encoding\n",
    "        impute_reshape = nonulls.reshape(-1,1)\n",
    "        #encode date\n",
    "        impute_ordinal = encoder.fit_transform(impute_reshape)\n",
    "        #Assign back encoded values to non-null values\n",
    "        data.loc[data.notnull()] = np.squeeze(impute_ordinal)\n",
    "        return {l: i for i, l in enumerate(encoder.classes_)}\n",
    "    \n",
    "    #encoder une caratéristique ordinale en utilisant une classe predéfinie LabelEncoder\n",
    "    def enOrdFeature(df,column):\n",
    "        label_encoder = LabelEncoder()\n",
    "        df[column] = label_encoder.fit_transform(df[column])\n",
    "        return {l: i for i, l in enumerate(label_encoder.classes_)}\n",
    "    \n",
    "    '''      \n",
    "    #encoder une classe binaire de type objet (str) par une nouvelle colonne ajoutée au DataFrame \n",
    "    def enBiFeature(self,column,newName,value):\n",
    "        self.df[newName] = np.where(self.df[column].str.contains(value), 1, 0)   \n",
    "    '''\n",
    "    \n",
    "    #encoder une caratéristique nominale en utilisant One Hot encoding\n",
    "    def enNomFeature(df,column):\n",
    "        one_hot = pd.get_dummies(df[column])\n",
    "        return one_hot\n",
    "       \n",
    "    def enOrFeatureByDict(df,column,dictFeature):\n",
    "        df[column].replace(to_replace = list(dictFeature.keys()), value =list(dictFeature.values()), inplace=True)\n",
    "        return dictFeature\n",
    "\n",
    "    #### Encoding categorical data ###\n",
    "    \n",
    "    \n",
    "    #### Decoding categorical data ###\n",
    "    \n",
    "    def decode(df,dictFeatures,column):\n",
    "        df[column].replace(to_replace = list(dictFeatures.values()), value =list(dictFeatures.keys()), inplace=True)\n",
    "        return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n    def imputeByPred(self,algorithm,inputCols,outputCol,knn = 3):\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"A\":[12, 7, 11, 8, \"-\"], \n",
    "                   \"B\":[70, 2, 54, 3, 2], \n",
    "                   \"C\":[20, 16, None, 3, 8], \n",
    "                   \"D\":[14, 3, None, None, 6],\n",
    "                   \"E\":[np.nan, 6, np.nan, None, 8]}) \n",
    "clas=MissingValues(df)\n",
    "#print(clas.meaninglessVals)\n",
    "clas.collectMisVal('none')\n",
    "#print(clas.meaninglessVals)\n",
    "\n",
    "\n",
    "#print(clas.getUniqueValues(\"A\"))\n",
    "\n",
    "\n",
    "#print(clas.replaceMeaninglessVals())\n",
    "#print(clas.read())\n",
    "\n",
    "\n",
    "#print(clas.replaceByRegex('^-$'))\n",
    "\n",
    "\n",
    "#print(clas.getInfCols())\n",
    "\n",
    "\n",
    "#print(clas.getColumnsType())\n",
    "\n",
    "\n",
    "#print(clas.fillna(\"A\",\"-\"))\n",
    "\n",
    "\n",
    "#print(clas.dropColumns([\"E\",\"D\"]))\n",
    "#print(clas.read())\n",
    "\n",
    "\n",
    "#print(clas.dropAutomColumns(0.6))\n",
    "#print(clas.read())\n",
    "\n",
    "\n",
    "#print(clas.dropRowsRo(3))\n",
    "#print(clas.read())\n",
    "\n",
    "\n",
    "#print(clas.dropRowsCo(3))\n",
    "#print(clas.read())\n",
    "\n",
    "\n",
    "#print(clas.interpolate(\"linear\",\"forward\"))\n",
    "#print(clas.read())\n",
    "\n",
    "\n",
    "#print(clas.imputeRandomly('D'))\n",
    "#print(clas.read())\n",
    "\n",
    "\n",
    "#print(clas.replaceByRegex('^-$'))\n",
    "#print(clas.imputeByStatiMeth(\"random\",\"C\"))\n",
    "\n",
    "\n",
    "#print(clas.imputeByPred(\"knn\",[\"B\"],\"C\"))\n",
    "#print(clas.read())\n",
    "\n",
    "\n",
    "#print(clas.imputeByPred(\"regression\",[\"B\"],\"C\"))\n",
    "#print(clas.read())\n",
    "\n",
    "\n",
    "#print(clas.imputeByPred(\"decisionTree\",[\"B\"],\"C\"))\n",
    "#print(clas.read())\n",
    "\n",
    "\n",
    "#print(clas.imputeByPred(\"randomForest\",[\"B\"],\"C\"))\n",
    "#print(clas.read())\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "    def imputeByPred(self,algorithm,inputCols,outputCol,knn = 3):\n",
    "'''   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B     C          D    E\n",
      "0  12  70  20.0  14.000000  NaN\n",
      "1   7   2  16.0   3.000000  6.0\n",
      "2  11  54   NaN  11.408163  NaN\n",
      "3   8   3   3.0   8.040816  NaN\n",
      "4   4   2   8.0   6.000000  8.0\n"
     ]
    }
   ],
   "source": [
    "dff = pd.DataFrame({\"A\":[12, 7, 11, 8, 4], \n",
    "                   \"B\":[70, 2, 54, 3, 2], \n",
    "                   \"C\":[20, 16, None, 3, 8], \n",
    "                   \"D\":[14, 3, None, None, 6],\n",
    "                   \"E\":[None, 6, None, None, 8]}) \n",
    "m=MissingValues(dff)\n",
    "#m.imputeByPred('regression',[\"A\",'B'],\"D\")\n",
    "m.imputeByPred('regression',\"A\",\"D\")\n",
    "print(m.read())\n",
    "#print(m.read())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uchiha\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\uchiha\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   patient  obs  treatment  score  color\n",
      "0      1.0  1.0        0.0    1.0    1.0\n",
      "1      1.0  2.0        1.0    2.0    0.0\n",
      "2      1.0  3.0        0.0    0.0    2.0\n",
      "3      2.0  1.0        1.0    2.0    0.0\n",
      "4      2.0  2.0        0.0    1.0    1.0\n"
     ]
    }
   ],
   "source": [
    "raw_data = {'patient': [1, 1, 1, 2, 2],\n",
    "        'obs': [1, 2, 3, 1, 2],\n",
    "        'treatment': [0, 1, 0, 1, 0],\n",
    "        'score': ['strong', 'weak', 'normal', 'weak', 'strong'],\n",
    "        'color':['green','blue','yellow','blue','green']}\n",
    "df = pd.DataFrame(raw_data, columns = ['patient', 'obs', 'treatment', 'score','color'])\n",
    "m = MissingValues(df)\n",
    "l = ['score','color']\n",
    "print(m.encodeImpute(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{'female': 0, 'male': 1}\n",
      "   patient  obs  treatment   score   color  gender\n",
      "0        1    1          0  strong   green       1\n",
      "1        1    2          1    weak    blue       0\n",
      "2        1    3          0  normal  yellow       1\n",
      "3        2    1          1    weak    blue       1\n",
      "4        2    2          0  strong   green       0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient</th>\n",
       "      <th>obs</th>\n",
       "      <th>treatment</th>\n",
       "      <th>score</th>\n",
       "      <th>color</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>strong</td>\n",
       "      <td>green</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>weak</td>\n",
       "      <td>blue</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>yellow</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>weak</td>\n",
       "      <td>blue</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>strong</td>\n",
       "      <td>green</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient  obs  treatment   score   color  gender\n",
       "0        1    1          0  strong   green    male\n",
       "1        1    2          1    weak    blue  female\n",
       "2        1    3          0  normal  yellow    male\n",
       "3        2    1          1    weak    blue    male\n",
       "4        2    2          0  strong   green  female"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = {'patient': [1, 1, 1, 2, 2],\n",
    "        'obs': [1, 2, 3, 1, 2],\n",
    "        'treatment': [0, 1, 0, 1, 0],\n",
    "        'score': ['strong', 'weak', 'normal', 'weak', 'strong'],\n",
    "        'color':['green','blue','yellow','blue','green'],\n",
    "           'gender':[\"male\",\"female\",\"male\",\"male\",\"female\"]}\n",
    "df = pd.DataFrame(raw_data, columns = ['patient', 'obs', 'treatment', 'score','color','gender'])\n",
    "m = MissingValues(df)\n",
    "decoder = m.enOrdFeature('gender')\n",
    "print(\"\\n\")\n",
    "print(decoder)\n",
    "print(m.read())\n",
    "m.decode(decoder,'gender')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'score'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = {'patient': [1, 1, 1, 2, 2],\n",
    "        'obs': [1, 2, 3, 1, 2],\n",
    "        'treatment': [0, 1, 0, 1, 0],\n",
    "        'score': ['strong', 'weak', 'normal', 'weak', 'strong'],\n",
    "        'color':['green','blue','yellow','blue','green']}\n",
    "df = pd.DataFrame(raw_data, columns = ['patient', 'obs', 'treatment', 'score','color'])\n",
    "m = MissingValues(df)\n",
    "m.enNomFeature(\"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{'strong': 3, 'normal': 2, 'weak': 1}\n",
      "   patient  obs  treatment  score   color  gender\n",
      "0        1    1          0      3   green    male\n",
      "1        1    2          1      1    blue  female\n",
      "2        1    3          0      2  yellow    male\n",
      "3        2    1          1      1    blue    male\n",
      "4        2    2          0      3   green  female\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient</th>\n",
       "      <th>obs</th>\n",
       "      <th>treatment</th>\n",
       "      <th>score</th>\n",
       "      <th>color</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>strong</td>\n",
       "      <td>green</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>weak</td>\n",
       "      <td>blue</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>yellow</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>weak</td>\n",
       "      <td>blue</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>strong</td>\n",
       "      <td>green</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient  obs  treatment   score   color  gender\n",
       "0        1    1          0  strong   green    male\n",
       "1        1    2          1    weak    blue  female\n",
       "2        1    3          0  normal  yellow    male\n",
       "3        2    1          1    weak    blue    male\n",
       "4        2    2          0  strong   green  female"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = {'patient': [1, 1, 1, 2, 2],\n",
    "        'obs': [1, 2, 3, 1, 2],\n",
    "        'treatment': [0, 1, 0, 1, 0],\n",
    "        'score': ['strong', 'weak', 'normal', 'weak', 'strong'],\n",
    "        'color':['green','blue','yellow','blue','green'],\n",
    "           'gender':[\"male\",\"female\",\"male\",\"male\",\"female\"]}\n",
    "df = pd.DataFrame(raw_data, columns = ['patient', 'obs', 'treatment', 'score','color','gender'])\n",
    "m = MissingValues(df)\n",
    "decoder = m.enOrFeatureByDict('score',{\"strong\":3,\"normal\":2,\"weak\":1})\n",
    "print(\"\\n\")\n",
    "print(decoder)\n",
    "print(m.read())\n",
    "m.decode(decoder,'score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['ok'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-604d58e60a54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m            'gender':[\"male\",\"female\",\"male\",\"male\",\"female\"]}\n\u001b[0;32m      9\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'patient'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'obs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'treatment'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'score'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'color'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'gender'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"obs\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"ok\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4115\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4116\u001b[0m             \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4117\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4118\u001b[0m         )\n\u001b[0;32m   4119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3912\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3913\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3914\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3916\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3944\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3945\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3946\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3947\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5338\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5339\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5340\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{} not found in axis\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5341\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5342\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['ok'] not found in axis\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "raw_data = {'patient': [1, 1, 1, 2, 2],\n",
    "        'obs': [1, 2, 3, 1, 2],\n",
    "        'treatment': [0, 1, 0, 1, 0],\n",
    "        'score': ['strong', 'weak', 'normal', 'weak', 'strong'],\n",
    "        'color':['green','blue','yellow','blue','green'],\n",
    "           'gender':[\"male\",\"female\",\"male\",\"male\",\"female\"]}\n",
    "df = pd.DataFrame(raw_data, columns = ['patient', 'obs', 'treatment', 'score','color','gender'])\n",
    "df.drop(columns=[\"obs\",\"ok\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
